{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb7fe4f4",
   "metadata": {},
   "source": [
    "**Importing libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "df0b0ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cb48f765",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filename = \"data/Book_Details.csv\"\n",
    "df = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f45c4c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16225, 15)\n",
      "   Unnamed: 0  book_id                                    cover_image_uri  \\\n",
      "0           0        1  https://images-na.ssl-images-amazon.com/images...   \n",
      "1           1        2  https://images-na.ssl-images-amazon.com/images...   \n",
      "2           2        3  https://images-na.ssl-images-amazon.com/images...   \n",
      "3           3        5  https://images-na.ssl-images-amazon.com/images...   \n",
      "4           4        6  https://images-na.ssl-images-amazon.com/images...   \n",
      "5           5        8  https://images-na.ssl-images-amazon.com/images...   \n",
      "6           6       10  https://images-na.ssl-images-amazon.com/images...   \n",
      "7           7       11  https://images-na.ssl-images-amazon.com/images...   \n",
      "8           8       13  https://images-na.ssl-images-amazon.com/images...   \n",
      "9           9       21  https://images-na.ssl-images-amazon.com/images...   \n",
      "\n",
      "                                      book_title  \\\n",
      "0         Harry Potter and the Half-Blood Prince   \n",
      "1      Harry Potter and the Order of the Phoenix   \n",
      "2          Harry Potter and the Sorcerer's Stone   \n",
      "3       Harry Potter and the Prisoner of Azkaban   \n",
      "4            Harry Potter and the Goblet of Fire   \n",
      "5              Harry Potter Boxed Set, Books 1-5   \n",
      "6                        Harry Potter Collection   \n",
      "7           The Hitchhiker’s Guide to the Galaxy   \n",
      "8  The Ultimate Hitchhiker’s Guide to the Galaxy   \n",
      "9           A Short History of Nearly Everything   \n",
      "\n",
      "                                        book_details  \\\n",
      "0  It is the middle of the summer, but there is a...   \n",
      "1  Harry Potter is about to start his fifth year ...   \n",
      "2  Harry Potter has no idea how famous he is. Tha...   \n",
      "3  Harry Potter, along with his best friends, Ron...   \n",
      "4  It is the summer holidays and soon Harry Potte...   \n",
      "5  Box Set containing Harry Potter and the Sorcer...   \n",
      "6  Six years of magic, adventure, and mystery mak...   \n",
      "7  Seconds before the Earth is demolished to make...   \n",
      "8  At last in paperback in one complete volume, h...   \n",
      "9  Bill Bryson describes himself as a reluctant t...   \n",
      "\n",
      "                                 format                      publication_info  \\\n",
      "0              ['652 pages, Paperback']     ['First published July 16, 2005']   \n",
      "1              ['912 pages, Paperback']     ['First published June 21, 2003']   \n",
      "2              ['309 pages, Hardcover']     ['First published June 26, 1997']   \n",
      "3  ['435 pages, Mass Market Paperback']      ['First published July 8, 1999']   \n",
      "4              ['734 pages, Paperback']      ['First published July 8, 2000']   \n",
      "5             ['2690 pages, Paperback']   ['First published October 1, 2003']   \n",
      "6             ['3342 pages, Hardcover']   ['First published January 1, 2005']   \n",
      "7  ['216 pages, Mass Market Paperback']  ['First published October 12, 1979']   \n",
      "8              ['815 pages, Paperback']  ['First published January 17, 1996']   \n",
      "9              ['544 pages, Paperback']   ['First published January 1, 2003']   \n",
      "\n",
      "                                          authorlink         author num_pages  \\\n",
      "0  https://www.goodreads.com/author/show/1077326....   J.K. Rowling   ['652']   \n",
      "1  https://www.goodreads.com/author/show/1077326....   J.K. Rowling   ['912']   \n",
      "2  https://www.goodreads.com/author/show/1077326....   J.K. Rowling   ['309']   \n",
      "3  https://www.goodreads.com/author/show/1077326....   J.K. Rowling   ['435']   \n",
      "4  https://www.goodreads.com/author/show/1077326....   J.K. Rowling   ['734']   \n",
      "5  https://www.goodreads.com/author/show/1077326....   J.K. Rowling  ['2690']   \n",
      "6  https://www.goodreads.com/author/show/1077326....   J.K. Rowling  ['3342']   \n",
      "7  https://www.goodreads.com/author/show/4.Dougla...  Douglas Adams   ['216']   \n",
      "8  https://www.goodreads.com/author/show/4.Dougla...  Douglas Adams   ['815']   \n",
      "9  https://www.goodreads.com/author/show/7.Bill_B...    Bill Bryson   ['544']   \n",
      "\n",
      "                                              genres  num_ratings  \\\n",
      "0  ['Fantasy', 'Young Adult', 'Fiction', 'Magic',...      3292516   \n",
      "1  ['Young Adult', 'Fiction', 'Magic', 'Childrens...      3401709   \n",
      "2  ['Fantasy', 'Fiction', 'Young Adult', 'Magic',...     10116247   \n",
      "3  ['Fantasy', 'Fiction', 'Young Adult', 'Magic',...      4215031   \n",
      "4  ['Fantasy', 'Young Adult', 'Fiction', 'Magic',...      3718209   \n",
      "5  ['Fantasy', 'Young Adult', 'Fiction', 'Magic',...       148443   \n",
      "6  ['Fantasy', 'Fiction', 'Young Adult', 'Magic',...        32990   \n",
      "7  ['Science Fiction', 'Fiction', 'Humor', 'Fanta...      1849362   \n",
      "8  ['Science Fiction', 'Fiction', 'Humor', 'Fanta...       323845   \n",
      "9  ['Nonfiction', 'Science', 'History', 'Audioboo...       387803   \n",
      "\n",
      "   num_reviews  average_rating  \\\n",
      "0        58398            4.58   \n",
      "1        64300            4.50   \n",
      "2       163493            4.47   \n",
      "3        84959            4.58   \n",
      "4        69961            4.57   \n",
      "5          313            4.72   \n",
      "6          974            4.72   \n",
      "7        46122            4.23   \n",
      "8         6355            4.38   \n",
      "9        15874            4.21   \n",
      "\n",
      "                                 rating_distribution  \n",
      "0  {'5': '2,244,154', '4': '775,028', '3': '219,8...  \n",
      "1  {'5': '2,178,760', '4': '856,178', '3': '293,2...  \n",
      "2  {'5': '6,544,542', '4': '2,348,390', '3': '856...  \n",
      "3  {'5': '2,892,322', '4': '970,190', '3': '287,7...  \n",
      "4  {'5': '2,500,070', '4': '899,496', '3': '259,7...  \n",
      "5  {'5': '120,035', '4': '19,721', '3': '5,489', ...  \n",
      "6  {'5': '26,491', '4': '4,731', '3': '1,183', '2...  \n",
      "7  {'5': '936,656', '4': '544,512', '3': '256,245...  \n",
      "8  {'5': '187,914', '4': '88,512', '3': '34,756',...  \n",
      "9  {'5': '184,880', '4': '130,221', '3': '51,751'...  \n",
      "Index(['Unnamed: 0', 'book_id', 'cover_image_uri', 'book_title',\n",
      "       'book_details', 'format', 'publication_info', 'authorlink', 'author',\n",
      "       'num_pages', 'genres', 'num_ratings', 'num_reviews', 'average_rating',\n",
      "       'rating_distribution'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16225 entries, 0 to 16224\n",
      "Data columns (total 15 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Unnamed: 0           16225 non-null  int64  \n",
      " 1   book_id              16225 non-null  int64  \n",
      " 2   cover_image_uri      16225 non-null  object \n",
      " 3   book_title           16225 non-null  object \n",
      " 4   book_details         16177 non-null  object \n",
      " 5   format               16225 non-null  object \n",
      " 6   publication_info     16225 non-null  object \n",
      " 7   authorlink           16225 non-null  object \n",
      " 8   author               16225 non-null  object \n",
      " 9   num_pages            16225 non-null  object \n",
      " 10  genres               16225 non-null  object \n",
      " 11  num_ratings          16225 non-null  int64  \n",
      " 12  num_reviews          16225 non-null  int64  \n",
      " 13  average_rating       16225 non-null  float64\n",
      " 14  rating_distribution  16225 non-null  object \n",
      "dtypes: float64(1), int64(4), object(10)\n",
      "memory usage: 1.9+ MB\n",
      "None\n",
      "Unnamed: 0              0\n",
      "book_id                 0\n",
      "cover_image_uri         0\n",
      "book_title              0\n",
      "book_details           48\n",
      "format                  0\n",
      "publication_info        0\n",
      "authorlink              0\n",
      "author                  0\n",
      "num_pages               0\n",
      "genres                  0\n",
      "num_ratings             0\n",
      "num_reviews             0\n",
      "average_rating          0\n",
      "rating_distribution     0\n",
      "dtype: int64\n",
      "Unnamed: 0               int64\n",
      "book_id                  int64\n",
      "cover_image_uri         object\n",
      "book_title              object\n",
      "book_details            object\n",
      "format                  object\n",
      "publication_info        object\n",
      "authorlink              object\n",
      "author                  object\n",
      "num_pages               object\n",
      "genres                  object\n",
      "num_ratings              int64\n",
      "num_reviews              int64\n",
      "average_rating         float64\n",
      "rating_distribution     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# print info\n",
    "print(df.shape)\n",
    "print(df.head(10))\n",
    "print(df.columns)\n",
    "print(df.info())\n",
    "print(df.isnull().sum())\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5dfcf50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select features\n",
    "df = df.drop(columns=['format', 'authorlink', 'num_reviews', 'rating_distribution'])\n",
    "\n",
    "# Sort by num_ratings \n",
    "df['num_ratings'] = pd.to_numeric(df['num_ratings'], errors='coerce')\n",
    "df = df.dropna(subset=['num_ratings'])\n",
    "# Get top 5000\n",
    "df = df.sort_values(by='num_ratings', ascending=False).head(5000).reset_index(drop=True)\n",
    "\n",
    "# format data\n",
    "df['publication_info'] = df['publication_info'].apply(lambda x: ast.literal_eval(x)[0] if isinstance(x, str) and x.startswith(\"['\") else x)\n",
    "df['publication_info'] = df['publication_info'].str.replace('^First published ', '', regex=True)\n",
    "\n",
    "df = df.dropna(subset=['num_pages'])\n",
    "def safe_num_pages(x):\n",
    "    if isinstance(x, str):\n",
    "        try:\n",
    "            parsed = ast.literal_eval(x)\n",
    "            if isinstance(parsed, list) and len(parsed) > 0:\n",
    "                return int(parsed[0])\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "    elif pd.isna(x):\n",
    "        return np.nan\n",
    "    else:\n",
    "        try:\n",
    "            return int(x)\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "\n",
    "df['num_pages'] = df['num_pages'].apply(safe_num_pages)\n",
    "df['num_pages'] = df['num_pages'].astype('Int64')  # pandas nullable integer dtype\n",
    "\n",
    "df['genres'] = df['genres'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dc8f30bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import json\n",
    "\n",
    "# --- TF-IDF setup ---\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "\n",
    "# Clean book_details column and reindex\n",
    "df['book_details'] = df['book_details'].fillna('')\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Fit and transform\n",
    "tfidf_matrix = vectorizer.fit_transform(df['book_details'])\n",
    "\n",
    "# Convert sparse matrix to list of vectors\n",
    "vectors = [tfidf_matrix[i].toarray()[0] for i in range(tfidf_matrix.shape[0])]\n",
    "\n",
    "# Add new column to df\n",
    "df = df.reset_index(drop=True)  # just to be safe\n",
    "df['vector'] = vectors\n",
    "\n",
    "# Build book data list\n",
    "book_data = []\n",
    "for idx, row in df.iterrows():\n",
    "    vector = tfidf_matrix[idx].toarray()[0].tolist()  # Convert sparse vector to list\n",
    "    book_data.append({\n",
    "        'book_title': row['book_title'],\n",
    "        'book_details': row['book_details'],\n",
    "        'num_pages': int(row['num_pages']) if not pd.isna(row['num_pages']) else None,\n",
    "        'publication_info': row['publication_info'],\n",
    "        'genres': row['genres'],\n",
    "        'book_id': row['book_id'],\n",
    "        'author': row['author'],\n",
    "        'average_rating': row['average_rating'],\n",
    "        'num_ratings': row['num_ratings'],\n",
    "        'cover_image_uri': row['cover_image_uri'],\n",
    "        'vector': vector\n",
    "    })\n",
    "\n",
    "# Save vector data to JSON\n",
    "with open('book_data.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(book_data, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8e8a954b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'book_id', 'cover_image_uri', 'book_title',\n",
      "       'book_details', 'publication_info', 'author', 'num_pages', 'genres',\n",
      "       'num_ratings', 'average_rating', 'vector'],\n",
      "      dtype='object')\n",
      "   Unnamed: 0   book_id                                    cover_image_uri  \\\n",
      "0           2         3  https://images-na.ssl-images-amazon.com/images...   \n",
      "1       15097  42844155  https://images-na.ssl-images-amazon.com/images...   \n",
      "2       12409  12885649  https://images-na.ssl-images-amazon.com/images...   \n",
      "3        9549   2767052  https://images-na.ssl-images-amazon.com/images...   \n",
      "4        2572     41865  https://images-na.ssl-images-amazon.com/images...   \n",
      "\n",
      "                              book_title  \\\n",
      "0  Harry Potter and the Sorcerer's Stone   \n",
      "1  Harry Potter and the Sorcerer’s Stone   \n",
      "2                       The Hunger Games   \n",
      "3                       The Hunger Games   \n",
      "4                               Twilight   \n",
      "\n",
      "                                        book_details    publication_info  \\\n",
      "0  Harry Potter has no idea how famous he is. Tha...       June 26, 1997   \n",
      "1  An alternative cover for this ASIN can be foun...       June 26, 1997   \n",
      "2  MAY THE ODDS BE EVER IN YOUR FAVOURWinning wil...  September 14, 2008   \n",
      "3  Could you survive on your own in the wild, wit...  September 14, 2008   \n",
      "4  About three things I was absolutely positive.F...     October 5, 2005   \n",
      "\n",
      "            author  num_pages  \\\n",
      "0     J.K. Rowling        309   \n",
      "1     J.K. Rowling        333   \n",
      "2  Suzanne Collins        458   \n",
      "3  Suzanne Collins        374   \n",
      "4  Stephenie Meyer        498   \n",
      "\n",
      "                                              genres  num_ratings  \\\n",
      "0  [Fantasy, Fiction, Young Adult, Magic, Childre...     10116247   \n",
      "1  [Fantasy, Fiction, Young Adult, Magic, Childre...     10113168   \n",
      "2  [Young Adult, Fiction, Fantasy, Science Fictio...      8719855   \n",
      "3  [Young Adult, Fiction, Fantasy, Science Fictio...      8717540   \n",
      "4  [Fantasy, Young Adult, Romance, Fiction, Vampi...      6610633   \n",
      "\n",
      "   average_rating                                             vector  \n",
      "0            4.47  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "1            4.47  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "2            4.34  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "3            4.34  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
      "4            3.65  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n"
     ]
    }
   ],
   "source": [
    "# check formatting\n",
    "features = df.columns\n",
    "print(features)\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbf9c09",
   "metadata": {},
   "source": [
    "**Compute User Vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1abf164e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_user_vector(user_about_me, liked_book_vectors, vectorizer):\n",
    "    # Vectorize 'about me' text\n",
    "    user_vec = vectorizer.transform([user_about_me]).toarray()[0]\n",
    "\n",
    "    if liked_book_vectors:\n",
    "        liked_avg = np.mean(liked_book_vectors, axis=0)\n",
    "        combined_vec = 0.5 * user_vec + 0.5 * liked_avg  \n",
    "    else:\n",
    "        combined_vec = user_vec\n",
    "\n",
    "    return combined_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d6698baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reccomenadtion function\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "def recommend_books(user_vec, books_df, filters):\n",
    "    # Filter books by genre overlap and page range\n",
    "    def genre_match(book_genres):\n",
    "        return bool(set(book_genres) & set(filters['genres']))\n",
    "    \n",
    "    filtered = books_df[\n",
    "        books_df['genres'].apply(genre_match) &\n",
    "        (books_df['num_pages'] >= filters['min_pages']) &\n",
    "        (books_df['num_pages'] <= filters['max_pages'])\n",
    "    ].copy()\n",
    "\n",
    "    if filtered.empty:\n",
    "        return pd.DataFrame()  # no matches\n",
    "\n",
    "    # Prepare matrix of book vectors\n",
    "    book_vecs = np.vstack(filtered['vector'].values)\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    sims = cosine_similarity([user_vec], book_vecs)[0]\n",
    "\n",
    "    filtered['similarity'] = sims\n",
    "\n",
    "    # Return top recommendations sorted by similarity\n",
    "    return filtered.sort_values('similarity', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f766a5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['18th Century', '19th Century', '20th Century', 'Abuse', 'Action', 'Adoption', 'Adult', 'Adult Fiction', 'Adventure', 'Africa', 'African American', 'African Literature', 'Aliens', 'Alternate History', 'American', 'American History', 'American Revolution', 'Amish', 'Ancient', 'Ancient History', 'Angels', 'Animals', 'Anime', 'Anthologies', 'Anthropology', 'Anti Racist', 'Apocalyptic', 'Archaeology', 'Architecture', 'Art', 'Art Design', 'Art History', 'Arthurian', 'Asia', 'Asian Literature', 'Astronomy', 'Atheism', 'Audiobook', 'Australia', 'Autistic Spectrum Disorder', 'Autobiography', 'Aviation', 'BDSM', 'Banned Books', 'Baseball', 'Basketball', 'Batman', 'Beauty and The Beast', 'Biography', 'Biography Memoir', 'Biology', 'Birds', 'Boarding School', 'Book Club', 'Books About Books', 'Botswana', 'Brain', 'Brazil', 'British Literature', 'Buddhism', 'Buisness', 'Business', 'Canada', 'Canadian Literature', 'Cats', 'Chapter Books', 'Chemistry', 'Chess', 'Chick Lit', 'Childrens', 'China', 'Christian', 'Christian Fiction', 'Christian Living', 'Christian Romance', 'Christianity', 'Christmas', 'Church', 'Civil War', 'Classic Literature', 'Classics', 'Clean Romance', 'Climate Change', 'Collections', 'College', 'Comedy', 'Comic Book', 'Comic Strips', 'Comics', 'Comics Manga', 'Coming Of Age', 'Comix', 'Communication', 'Computer Science', 'Contemporary', 'Contemporary Romance', 'Cookbooks', 'Cooking', 'Counting', 'Cozy Mystery', 'Crime', 'Culinary', 'Cults', 'Cultural', 'Cyberpunk', 'Czech Literature', 'Dark', 'Dark Fantasy', 'Dc Comics', 'Death', 'Demons', 'Denmark', 'Design', 'Detective', 'Diary', 'Dinosaurs', 'Disability', 'Dogs', 'Dragonlance', 'Dragons', 'Drama', 'Drawing', 'Dungeons and Dragons', 'Dystopia', 'Ecology', 'Economics', 'Education', 'Egypt', 'Engineering', 'Entrepreneurship', 'Environment', 'Epic', 'Epic Fantasy', 'Erotic Romance', 'Erotica', 'Espionage', 'Essays', 'Ethiopia', 'European History', 'Evolution', 'Fae', 'Fairies', 'Fairy Tales', 'Faith', 'Family', 'Fan Fiction', 'Fantasy', 'Fantasy Romance', 'Feminism', 'Fiction', 'Fighters', 'Finance', 'Fitness', 'Folklore', 'Food', 'Food and Drink', 'Foodie', 'Football', 'Forgotten Realms', 'France', 'French Literature', 'Futuristic', 'Gardening', 'Gay', 'Gender', 'Genetics', 'Geography', 'German Literature', 'Germany', 'Ghosts', 'Gothic', 'Graphic Novels', 'Graphic Novels Comics', 'Greece', 'Greek Mythology', 'Guides', 'Halloween', 'Hard Science Fiction', 'Health', 'High Fantasy', 'High School', 'Hinduism', 'Historical', 'Historical Fantasy', 'Historical Fiction', 'Historical Mystery', 'Historical Romance', 'History', 'History Of Science', 'Hockey', 'Holiday', 'Holocaust', 'Horror', 'Horses', 'How To', 'Hugo Awards', 'Humor', 'Hungary', 'India', 'Indian Literature', 'Inspirational', 'Iran', 'Ireland', 'Irish Literature', 'Islam', 'Israel', 'Italian Literature', 'Italy', 'Japan', 'Japanese Literature', 'Jewish', 'Journalism', 'Judaism', 'Juvenile', 'Kids', 'Knitting', 'LGBT', 'Language', 'Latin American', 'Latin American Literature', 'Law', 'Lds', 'Leadership', 'Legal Thriller', 'Lesbian', 'Linguistics', 'Literary Fiction', 'Literature', 'Love', 'Love Story', 'Lovecraftian', 'M M Romance', 'Magic', 'Magical Realism', 'Management', 'Manga', 'Marriage', 'Martial Arts', 'Marvel', 'Mathematics', 'Media Tie In', 'Medical', 'Medicine', 'Medieval', 'Memoir', 'Mental Health', 'Mental Illness', 'Mermaids', 'Middle Grade', 'Military Fiction', 'Military History', 'Money', 'Monsters', 'Motorcycle', 'Mountaineering', 'Murder Mystery', 'Music', 'Mystery', 'Mystery Thriller', 'Mythology', 'Native Americans', 'Nature', 'Neuroscience', 'New Adult', 'New Age', 'New Weird', 'New York', 'Nigeria', 'Nobel Prize', 'Noir', 'Nonfiction', 'Nordic Noir', 'Novella', 'Novels', 'Nutrition', 'Paranormal', 'Paranormal Romance', 'Parenting', 'Personal Development', 'Personal Finance', 'Philosophy', 'Photography', 'Physics', 'Picture Books', 'Pirates', 'Plays', 'Poetry', 'Poland', 'Polish Literature', 'Political Science', 'Politics', 'Pop Culture', 'Popular Science', 'Portugal', 'Portuguese Literature', 'Post Apocalyptic', 'Poverty', 'Prayer', 'Prehistoric', 'Presidents', 'Productivity', 'Psychoanalysis', 'Psychological Thriller', 'Psychology', 'Pulp', 'Queer', 'Race', 'Read For School', 'Realistic Fiction', 'Reference', 'Regency', 'Relationships', 'Religion', 'Retellings', 'Reverse Harem', 'Road Trip', 'Robots', 'Rock N Roll', 'Romance', 'Romantic', 'Romantic Suspense', 'Romanticism', 'Russia', 'Russian History', 'Russian Literature', 'Scandinavian Literature', 'School', 'Science', 'Science Fiction', 'Science Fiction Fantasy', 'Scotland', 'Seinen', 'Self Help', 'Sexuality', 'Shapeshifters', 'Short Stories', 'Skepticism', 'Social', 'Social Justice', 'Society', 'Sociology', 'South Africa', 'Southern', 'Southern Gothic', 'Space', 'Space Opera', 'Spain', 'Spanish Literature', 'Speculative Fiction', 'Spirituality', 'Sports', 'Sports Romance', 'Spy Thriller', 'Star Wars', 'Steampunk', 'Storytime', 'Street Art', 'Sudan', 'Superheroes', 'Superman', 'Supernatural', 'Survival', 'Suspense', 'Sweden', 'Taoism', 'Teaching', 'Technology', 'Teen', 'The United States Of America', 'Theatre', 'Theology', 'Theory', 'Thriller', 'Time Travel', 'Trains', 'Transgender', 'Transport', 'Travel', 'Travelogue', 'True Crime', 'True Story', 'Tudor Period', 'Turkish', 'Turkish Literature', 'Ukraine', 'Unfinished', 'Urban Fantasy', 'Vampires', 'Vegan', 'Victorian', 'War', 'Werewolves', 'Westerns', 'Witches', 'Womens', 'Womens Fiction', 'World History', 'World War I', 'World War II', 'Writing', 'Young Adult', 'Young Adult Contemporary', 'Young Adult Fantasy', 'Young Adult Romance', 'Zimbabwe', 'Zombies']\n"
     ]
    }
   ],
   "source": [
    "# If genres are already lists\n",
    "from itertools import chain\n",
    "\n",
    "all_genres = sorted(set(chain.from_iterable(df['genres'])))\n",
    "\n",
    "# To view them sorted\n",
    "print(all_genres)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7dce90d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            book_title  \\\n",
      "25                              The Catcher in the Rye   \n",
      "10                                                1984   \n",
      "2970                             The Only Good Indians   \n",
      "4170                       At the Mountains of Madness   \n",
      "1764                               The Ersatz Elevator   \n",
      "3288  The Cat in the Hat and Other Dr. Seuss Favorites   \n",
      "4383       The Call of Cthulhu and Other Weird Stories   \n",
      "114                         The Picture of Dorian Gray   \n",
      "2677                                         Columbine   \n",
      "3926                             Cycle of the Werewolf   \n",
      "\n",
      "                                                 genres  similarity  \n",
      "25    [Classics, Fiction, Young Adult, Literature, S...    0.456416  \n",
      "10    [Classics, Fiction, Science Fiction, Dystopia,...    0.411411  \n",
      "2970  [Horror, Fiction, Thriller, Audiobook, Fantasy...    0.408487  \n",
      "4170  [Horror, Fiction, Classics, Science Fiction, F...    0.364531  \n",
      "1764  [Fiction, Young Adult, Childrens, Middle Grade...    0.305580  \n",
      "3288  [Childrens, Picture Books, Classics, Fiction, ...    0.303271  \n",
      "4383  [Horror, Fiction, Classics, Short Stories, Fan...    0.295854  \n",
      "114   [Classics, Fiction, Horror, Fantasy, Gothic, L...    0.290410  \n",
      "2677  [Nonfiction, True Crime, History, Crime, Audio...    0.278866  \n",
      "3926  [Horror, Fiction, Fantasy, Werewolves, Thrille...    0.277487  \n"
     ]
    }
   ],
   "source": [
    "# Example user input:\n",
    "user_about_me = \"I wanna read something very scary that will keep me up at night. I like horror specifically psychological horror and thrillers.\"\n",
    "liked_books_vectors = [book_data[10]['vector'], book_data[25]['vector']]  # example liked books vectors\n",
    "\n",
    "\n",
    "filters = {\n",
    "    'genres': all_genres,  # default: include all\n",
    "    'min_pages': 0,\n",
    "    'max_pages': 10000\n",
    "}\n",
    "\n",
    "user_vec = compute_user_vector(user_about_me, liked_books_vectors, vectorizer)\n",
    "recommendations = recommend_books(user_vec, df, filters)\n",
    "\n",
    "print(recommendations[['book_title', 'genres', 'similarity']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e595ee61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Exported JSON files: book_data.json, tfidf_vocab.json, unique_genres.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming your vectorizer is named 'vectorizer' and your df has a 'vector' column\n",
    "# Convert NumPy arrays in 'vector' column to lists\n",
    "df['vector'] = df['vector'].apply(lambda x: x.tolist() if hasattr(x, 'tolist') else x)\n",
    "\n",
    "\n",
    "# 1. Export book data (metadata + vector)\n",
    "book_data_export = df[['book_title', 'book_details', 'num_pages', 'genres', 'vector']].to_dict(orient='records')\n",
    "with open('book_data.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(book_data_export, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# 2. Export vocabulary of your TF-IDF vectorizer\n",
    "# Convert keys and values to native Python types (str and int)\n",
    "vocab_clean = {str(k): int(v) for k, v in vectorizer.vocabulary_.items()}\n",
    "\n",
    "with open('tfidf_vocab.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(vocab_clean, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# 3. Export unique genres (for filters)\n",
    "from itertools import chain\n",
    "unique_genres = sorted(set(chain.from_iterable(df['genres'])))\n",
    "with open('unique_genres.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(unique_genres, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\" Exported JSON files: book_data.json, tfidf_vocab.json, unique_genres.json\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
